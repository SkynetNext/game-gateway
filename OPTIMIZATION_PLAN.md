# Game-Gateway 性能优化与架构落地计划

本文档旨在指导 game-gateway 的后续性能压测及云原生底座深度优化，通过量化指标验证系统在高并发场景下的稳定性与低延迟表现。

## 核心目标
1. **量化性能表现**：通过压力测试获取系统处理能力的基准数据（Throughput/Latency）。
2. **底层网络调优**：落地 HostNetwork 方案，评估其在避开 CNI 损耗、提升网络吞吐方面的实际收益。
3. **完善观测链路**：打通网关至后端服务的全链路 Trace 追踪，提升系统透明度。

---

## 第一阶段：基准压测与弹性验证 (优先级：最高)
**任务描述**：验证当前架构在压力下的表现及 HPA 的响应速度。
*   **动作**：使用 K6 或 Jmeter 对 game-gateway 进行梯度压测。
*   **关注指标**：
    *   单实例 QPS 极限。
    *   P99 延迟随并发量增长的曲线。
    *   HPA 触发后，新 Pod 就绪到流量均衡的耗时。
*   **价值**：产出基准性能报告，证明系统“韧性”。

## 第二阶段：确定性网络方案落地 (核心技术差异点)
**任务描述**：弃用 ClusterIP，改用 HostNetwork 以追求极致低延迟。
*   **动作**：
    1. 修改 StatefulSet 配置，启用 `hostNetwork: true`。
    2. 实现基于 **Pod Ordinal (序号)** 的端口确定性分配（如 Pod-0 映射 10000，Pod-1 映射 10001）。
    3. 再次进行压测，对比第一阶段数据。
*   **价值**：量化 HostNetwork 带来的延迟收益（预计降低 10-15%），体现对 K8s 网络底层的深度调优能力。

## 第三阶段：全链路观测深度打通 (系统深度指标)
**任务描述**：完善 OpenTelemetry 链路，确保 Trace 能够透传至后端 C++ 服务。
*   **动作**：
    1. 在 game-gateway 侧确保 TraceContext (W3C Standard) 正确注入 Header。
    2. (可选) 在 C++ 后端解析 Header 并串联日志。
    3. 利用 Consul 动态权重或健康检查，实现“延迟过高自动摘除”的闭环逻辑。
*   **价值**：体现对分布式系统稳定性治理（Observability + Service Discovery）的成熟方法论。

---

## 执行路径 (明天建议顺序)
1. **Baseline**：先测出目前走 Service 的性能数据。
2. **Switch**：切换至 HostNetwork 模式并配置确定性端口。
3. **Compare**：对比数据，记录差异，这将是面试时最有力的说服工具。

